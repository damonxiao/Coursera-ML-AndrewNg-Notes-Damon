{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习的建议"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型选择和训练,验证,测试集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1. 数据集的划分:  \n",
    "一般情况上,按比例划分为训练集(60%),交叉验证集(20%),测试集(20%)\n",
    "* 2. 对应的误差函数  \n",
    "Training error:  \n",
    "$$\n",
    "J_{train}(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}{\\left({h_\\theta(x^{(i)}) - y^{(i)}}\\right)}^2\n",
    "$$\n",
    "Cross Validation error:  \n",
    "$$\n",
    "J_{cv}(\\theta) = \\frac{1}{2m_{cv}}\\sum_{i=1}^{m_{cv}}{\\left({h_\\theta(x_{cv}^{(i)}) - y_{cv}^{(i)}}\\right)}^2\n",
    "$$\n",
    "Test error:  \n",
    "$$\n",
    "J_{test}(\\theta) = \\frac{1}{2m_{test}}\\sum_{i=1}^{m_{test}}{\\left({h_\\theta(x_{test}^{(i)}) - y_{test}^{(i)}}\\right)}^2\n",
    "$$\n",
    "* 3. 模型选取方法\n",
    "在一系列模型函数(假设候选函数中有一次,二次,三次,n次函数)中使用$J_{cv}(\\theta)$来验证,取得$minJ(\\theta)$的模型函数即为最终选取的模型函数\n",
    "* 4. 交叉验证的意义\n",
    "独立开验证集和测试集的意义在于,不使用同一个数据集去验证和测试数据,使得模型的选取更容易更好的进行拟合."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 诊断偏差与方差\n",
    "* 1. 当训练误差(training error)与交叠验证误差(cross validation error)都很大时,则发生了欠拟合(算法有偏差问题(Bias) underfit),需要选用更高阶的多项式来进行训练和验证  \n",
    "*此时的$J_{cv}(\\theta)约等于J_{train}(\\theta)$*\n",
    "* 2. 当训练误差(training error)比较小,而交叠验证误差(cross validation error)比较大时,则发生了过拟合(算法有方差问题(Variance)overfit),需要选用稍低阶的多项式来进行训练和验证  \n",
    "*此时的$J_{cv}(\\theta)大于J_{train}(\\theta)比较多$*\n",
    "\n",
    "对应的课程截图如下\n",
    "![](../images/diagnosing_bias_vs_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正则化和偏差,方差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 选择正则化参数$\\lambda$\n",
    "假设选择的模型假设函数为  \n",
    "$$\n",
    "h_\\theta(x)= \\theta_0 + \\theta_1x+ \\theta_2x^2 + \\theta_3x^3 + \\theta_4x^4\n",
    "$$  \n",
    "模型代价函数为  \n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}\\left({h_\\theta(x^{(i)}) - y^{(i)}}\\right)^2 + \\frac{\\lambda}{2m}\\sum_{j=1}^{m}\\theta_j^2\n",
    "$$  \n",
    "对应的$J_{train}(\\theta)$,$J_{cv}(\\theta)$,$J_{test}(\\theta)$分别舍弃掉$\\lambda$的正则项后如下,舍弃正则项是为了在没有正则项时去验证对应合适的$\\lambda$参数  \n",
    "Training error:  \n",
    "$$\n",
    "J_{train}(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}{\\left({h_\\theta(x^{(i)}) - y^{(i)}}\\right)}^2\n",
    "$$\n",
    "Cross Validation error:  \n",
    "$$\n",
    "J_{cv}(\\theta) = \\frac{1}{2m_{cv}}\\sum_{i=1}^{m_{cv}}{\\left({h_\\theta(x_{cv}^{(i)}) - y_{cv}^{(i)}}\\right)}^2\n",
    "$$\n",
    "Test error:  \n",
    "$$\n",
    "J_{test}(\\theta) = \\frac{1}{2m_{test}}\\sum_{i=1}^{m_{test}}{\\left({h_\\theta(x_{test}^{(i)}) - y_{test}^{(i)}}\\right)}^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**$\\lambda$选取方法**  \n",
    "如课程截图,假设尝试$\\lambda$从[0,0.01,0.02,0.04,0.08,...10]这个数列中依次使用$J_{cv}(\\theta)$进行验证,这里假设$\\Theta^{(5)}$为12个模型中交叉验证集误差最小的,从这里可以看出,当$\\lambda = 0.08$时交叉验证集误差,取其为最终选择.  \n",
    "然后再将$\\Theta^{(5)}$代入到$J_{test}(\\theta)$中计算测试误差值,用以观察其在测试集上的表现,可以看出其在新样本上的泛化能力.\n",
    "\n",
    "课程截图\n",
    "![](../images/choosing_regularization_parameter_lambda.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 偏差(bias)与方差(variance)和$\\lambda$的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始带有正则项的$J(\\theta)$  \n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^{m}\\left({h_\\theta(x^{(i)}) - y^{(i)}}\\right)^2 + \\frac{\\lambda}{2m}\\sum_{j=1}^{m}\\theta_j^2\n",
    "$$\n",
    "\n",
    "Cross Validation error:  \n",
    "$$\n",
    "J_{cv}(\\theta) = \\frac{1}{2m_{cv}}\\sum_{i=1}^{m_{cv}}{\\left({h_\\theta(x_{cv}^{(i)}) - y_{cv}^{(i)}}\\right)}^2\n",
    "$$\n",
    "\n",
    "Test error:  \n",
    "$$\n",
    "J_{test}(\\theta) = \\frac{1}{2m_{test}}\\sum_{i=1}^{m_{test}}{\\left({h_\\theta(x_{test}^{(i)}) - y_{test}^{(i)}}\\right)}^2\n",
    "$$\n",
    "\n",
    "这里把$J_{cv}(\\theta)$和$J_{test}(\\theta)$中的正则项都去掉了,课程中右侧的两条曲线表示的是当正则项$\\lambda$发生变化时,对应的$J_{cv}(\\theta)$和$J_{test}(\\theta)$的变化曲线,由图中曲线可知,当$\\lambda$过大或过小时都无法很好的拟合,过大时发生欠拟合(underfit两条曲线接近,但是取値不是最小,高偏差(bias)),过小时发生过拟合(overfit,两条曲线相去甚远,高方差(variance)),**仅仅在中间时有一段是比较合适的$\\lambda$**  \n",
    "课程截图![](../images/bias_variance_of_regularization_parameter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调试和解决学习算法中遇到的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 解决高偏差(high bias)问题----欠拟合\n",
    "    1. 适当增加特征个数\n",
    "    2. 适当减小正则参数$\\lambda$值\n",
    "    2. 适当增加多项式的特征数(与增加特征个数类似)\n",
    "2. 解决高方差(high variance)问题----过拟合\n",
    "    1. 获取更多的训练样本数\n",
    "    2. 适当的减少特征数\n",
    "    3. 适当增大与正则参数$\\lambda$的值  \n",
    "\n",
    "<u>对应的课程截图如下</u>\n",
    "![](../images/debugging_a_learning_algorithm.png)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "tfpy3",
   "language": "python",
   "name": "tfpy3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
